{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a practice of SciKit-Learn of data science analysis. The data set is from Kaggle.com.\n",
    "\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data which consists of the features and labels.\n",
    "train_data = pd.read_csv(\"./data/train.csv\", header = None)\n",
    "train_label = pd.read_csv(\"./data/trainLabels.csv\", header = None)\n",
    "\n",
    "# Load test data.\n",
    "test_data = pd.read_csv(\"./data/test.csv\", header = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of training data: (1000, 40)\n",
      "description of training data:\n",
      "                0            1            2            3            4   \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.025596    -0.024526    -0.024088    -0.002271     1.092329   \n",
      "std       1.008282     1.016298     0.979109     0.970575     4.538834   \n",
      "min      -3.365711    -3.492086    -2.695602    -3.460471   -16.421901   \n",
      "25%      -0.669010    -0.693937    -0.698830    -0.617557    -1.801997   \n",
      "50%       0.027895    -0.033194     0.008145     0.002327     0.862818   \n",
      "75%       0.762520     0.682753     0.661434     0.640743     3.843172   \n",
      "max       3.326246     3.583870     2.546507     3.088738    17.565345   \n",
      "\n",
      "                5            6            7            8            9   ...  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  ...   \n",
      "mean     -0.006250     0.497342    -0.037883     0.026391    -0.003597  ...   \n",
      "std       0.989128     2.118819     2.232256     1.001064     1.013520  ...   \n",
      "min      -3.041250    -7.224761    -6.509084    -3.145588    -2.749812  ...   \n",
      "25%      -0.732265    -0.838619    -1.604037    -0.677562    -0.682220  ...   \n",
      "50%       0.027041     0.582321     0.018809     0.022092    -0.036110  ...   \n",
      "75%       0.671456     1.913664     1.438304     0.741310     0.665364  ...   \n",
      "max       3.102997     7.592666     7.130097     3.145258     3.919426  ...   \n",
      "\n",
      "                30           31           32           33           34  \\\n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
      "mean      0.030651     0.022951    -0.542491    -0.011608    -0.483507   \n",
      "std       1.011645     1.001375     2.239939     1.022456     2.121281   \n",
      "min      -3.379194    -2.971125    -7.840890    -2.999564    -7.124105   \n",
      "25%      -0.659457    -0.696032    -2.121943    -0.664550    -1.879247   \n",
      "50%       0.049416     0.049778    -0.568262    -0.028097    -0.493575   \n",
      "75%       0.747031     0.699917     0.939348     0.651374     1.005795   \n",
      "max       2.844792     3.688047     7.160379     3.353631     6.005818   \n",
      "\n",
      "                35           36           37           38           39  \n",
      "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000  \n",
      "mean      0.033371     0.567185     0.006849    -0.892659     0.609451  \n",
      "std       1.007044     2.227876     0.997635     2.022022     2.045439  \n",
      "min      -2.952358    -5.452254    -3.473913    -8.051722    -7.799086  \n",
      "25%      -0.642861    -1.059786    -0.691162    -2.220126    -0.565041  \n",
      "50%       0.037732     0.455474     0.038284    -0.855470     0.779944  \n",
      "75%       0.691800     2.122157     0.693535     0.388698     1.992193  \n",
      "max       3.420561     6.603499     3.492548     5.774120     6.803984  \n",
      "\n",
      "[8 rows x 40 columns]\n",
      "the first 5 samples:\n",
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.299403 -1.226624  1.498425 -1.176150  5.289853  0.208297  2.404498   \n",
      "1 -1.174176  0.332157  0.949919 -1.285328  2.199061 -0.151268 -0.427039   \n",
      "2  1.192222 -0.414371  0.067054 -2.233568  3.658881  0.089007  0.203439   \n",
      "3  1.573270 -0.580318 -0.866332 -0.603812  3.125716  0.870321 -0.161992   \n",
      "4 -0.613071 -0.644204  1.112558 -0.032397  3.490142 -0.011935  1.443521   \n",
      "\n",
      "         7         8         9   ...        30        31        32        33  \\\n",
      "0  1.594506 -0.051608  0.663234  ... -0.850465 -0.622990 -1.833057  0.293024   \n",
      "1  2.619246 -0.765884 -0.093780  ... -0.819750  0.012037  2.038836  0.468579   \n",
      "2 -4.219054 -1.184919 -1.240310  ... -0.604501  0.750054 -3.360521  0.856988   \n",
      "3  4.499666  1.038741 -1.092716  ...  1.022959  1.275598 -3.480110 -1.065252   \n",
      "4 -4.290282 -1.761308  0.807652  ...  0.513906 -1.803473  0.518579 -0.205029   \n",
      "\n",
      "         34        35        36        37        38        39  \n",
      "0  3.552681  0.717611  3.305972 -2.715559 -2.682409  0.101050  \n",
      "1 -0.517657  0.422326  0.803699  1.213219  1.382932 -1.817761  \n",
      "2 -2.751451 -1.582735  1.672246  0.656438 -0.932473  2.987436  \n",
      "3  2.153133  1.563539  2.767117  0.215748  0.619645  1.883397  \n",
      "4 -4.744566 -1.520015  1.830651  0.870772 -1.894609  0.408332  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape of training data: {train_data.shape}\")\n",
    "print(f\"description of training data:\\n{train_data.describe()}\")\n",
    "print(f\"the first 5 samples:\\n{train_data.head()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training / test sets\n",
    "x_train, x_val, y_train, y_val = train_test_split(train_data,\n",
    "                                                  train_label,\n",
    "                                                  test_size=0.25,\n",
    "                                                  random_state=4\n",
    "                                                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.892\n"
     ]
    }
   ],
   "source": [
    "# Establish Gradient Boosting Classifier model\n",
    "classifier = GradientBoostingClassifier(loss = 'deviance',    # loss function to be optimized\n",
    "                                        learning_rate = 0.1,\n",
    "                                        n_estimators = 100,   # The number of boosting stages to perform\n",
    "                                        criterion = 'friedman_mse'\n",
    "                                       )\n",
    "\n",
    "# train model on training set\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# predict test set\n",
    "y_pred = classifier.predict(x_val)\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Search with Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, None],\n",
      " 'max_features': ['sqrt', 'log2', None],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "\n",
    "# Number of features to consider at every split\n",
    "max_features = ['sqrt', 'log2', None]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(5, 50, num = 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               }\n",
    "\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   14.9s\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   43.1s finished\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 50 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = classifier,\n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 50,\n",
    "                               # scoring='neg_mean_absolute_error',\n",
    "                               cv = 3,\n",
    "                               verbose = 2,\n",
    "                               random_state = 42,\n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(x_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best score: 0.872\n",
      "the best parameters:\n",
      "{'n_estimators': 900, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}\n",
      "\n",
      "the cross validation result:\n",
      "{'mean_fit_time': array([1.68492198, 0.62570842, 1.41511075, 0.5870928 , 0.98637644,\n",
      "       0.6369915 , 0.82896058, 1.2124668 , 1.36618821, 0.8067228 ,\n",
      "       0.9803768 , 0.46770302, 1.29338344, 1.61834979, 0.59351865,\n",
      "       0.80501548, 0.85136803, 0.81166991, 0.81134693, 0.55818311,\n",
      "       1.47131817, 0.76717607, 1.36279837, 1.5773836 , 0.59965944,\n",
      "       0.70703634, 1.59629544, 0.53787533, 0.78666202, 0.84336662,\n",
      "       0.87835526, 1.57327628, 1.54287728, 0.6748534 , 0.99337943,\n",
      "       0.63269869, 0.78437527, 0.60032852, 1.34182795, 0.61681326,\n",
      "       0.83139873, 0.77941664, 0.64904507, 1.03622476, 0.92968551,\n",
      "       0.84700545, 1.33263516, 0.82904832, 1.2430106 , 0.67020551]), 'std_fit_time': array([0.03711487, 0.01294743, 0.01920036, 0.01375295, 0.02409599,\n",
      "       0.0157638 , 0.01201591, 0.02472606, 0.04511582, 0.02782901,\n",
      "       0.02950351, 0.01535903, 0.05285806, 0.01815564, 0.02638245,\n",
      "       0.01601649, 0.01393177, 0.00850854, 0.02469146, 0.00919141,\n",
      "       0.01031718, 0.01728932, 0.01001892, 0.01303491, 0.02355216,\n",
      "       0.00704683, 0.01271071, 0.01288781, 0.0133994 , 0.0204044 ,\n",
      "       0.00947429, 0.04875426, 0.01260981, 0.01155595, 0.00553578,\n",
      "       0.01345192, 0.00250317, 0.01313133, 0.07089422, 0.00915638,\n",
      "       0.0279362 , 0.01375654, 0.01209884, 0.02401798, 0.01014392,\n",
      "       0.00616739, 0.03171569, 0.00777719, 0.02955605, 0.03861967]), 'mean_score_time': array([0.00432404, 0.00468278, 0.00451175, 0.00398882, 0.00468667,\n",
      "       0.00433127, 0.00268404, 0.00383981, 0.00401409, 0.00517019,\n",
      "       0.00367896, 0.00550246, 0.00449093, 0.00501641, 0.00466132,\n",
      "       0.00450341, 0.00500377, 0.00600704, 0.00265932, 0.00500433,\n",
      "       0.00466482, 0.00482647, 0.00416946, 0.004685  , 0.00398898,\n",
      "       0.00383464, 0.00432165, 0.00516462, 0.00534058, 0.00534002,\n",
      "       0.00531983, 0.00566045, 0.00532111, 0.00434065, 0.00515946,\n",
      "       0.00431856, 0.00466069, 0.00434542, 0.00367514, 0.00418107,\n",
      "       0.00467563, 0.0043331 , 0.00564702, 0.00349283, 0.00466895,\n",
      "       0.00499495, 0.0041608 , 0.00498335, 0.00416907, 0.00398914]), 'std_score_time': array([4.88341485e-04, 4.70034716e-04, 4.14216143e-04, 1.12391596e-07,\n",
      "       4.72945278e-04, 4.64158147e-04, 4.59375142e-04, 2.42451442e-04,\n",
      "       1.79288376e-05, 2.36051277e-04, 9.47628334e-04, 3.19031834e-03,\n",
      "       4.03415994e-04, 2.61416184e-06, 4.75581543e-04, 3.93254966e-04,\n",
      "       1.96666025e-05, 2.16520271e-03, 4.70021695e-04, 7.09820343e-04,\n",
      "       4.77923203e-04, 6.28917613e-04, 2.35782434e-04, 4.72987463e-04,\n",
      "       6.74349576e-07, 6.34667849e-04, 4.69797033e-04, 6.30989112e-04,\n",
      "       4.77285929e-04, 1.24983742e-03, 4.70190494e-04, 1.71459081e-03,\n",
      "       4.59671075e-04, 4.78579675e-04, 2.43721351e-04, 4.73020311e-04,\n",
      "       4.75949627e-04, 4.54194631e-04, 4.83283863e-04, 6.35192269e-04,\n",
      "       4.85712229e-04, 4.87499024e-04, 2.35342948e-03, 4.07651570e-04,\n",
      "       4.80313306e-04, 1.31113360e-05, 6.15645996e-04, 6.18460225e-06,\n",
      "       6.16735158e-04, 8.14880182e-04]), 'param_n_estimators': masked_array(data=[900, 300, 400, 300, 700, 200, 100, 300, 300, 1000, 400,\n",
      "                   300, 700, 900, 400, 800, 900, 800, 200, 500, 800, 700,\n",
      "                   300, 900, 200, 100, 1000, 400, 900, 300, 1000, 900,\n",
      "                   1000, 1000, 1000, 500, 700, 100, 200, 200, 500, 700,\n",
      "                   900, 900, 700, 1000, 300, 900, 700, 800],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[10, 10, 2, 2, 2, 10, 5, 5, 2, 5, 5, 2, 2, 5, 2, 10, 5,\n",
      "                   2, 2, 10, 10, 2, 2, 5, 10, 5, 2, 2, 10, 2, 2, 2, 10, 2,\n",
      "                   5, 10, 2, 10, 2, 2, 5, 10, 2, 2, 5, 10, 10, 10, 5, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_leaf': masked_array(data=[2, 2, 4, 4, 2, 1, 1, 1, 4, 4, 1, 1, 4, 4, 1, 2, 4, 4,\n",
      "                   1, 2, 4, 4, 4, 4, 2, 1, 2, 4, 4, 2, 4, 2, 4, 1, 1, 4,\n",
      "                   4, 1, 2, 4, 2, 1, 1, 1, 1, 2, 4, 2, 4, 4],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_features': masked_array(data=[None, 'log2', None, 'sqrt', 'log2', 'sqrt', None, None,\n",
      "                   None, 'log2', None, 'sqrt', None, None, 'log2', 'sqrt',\n",
      "                   'log2', 'log2', None, 'log2', None, 'sqrt', None, None,\n",
      "                   'sqrt', 'sqrt', None, 'sqrt', 'log2', 'log2', 'sqrt',\n",
      "                   None, None, 'log2', 'sqrt', 'sqrt', 'log2', 'sqrt',\n",
      "                   None, 'sqrt', 'log2', 'log2', 'log2', None, 'sqrt',\n",
      "                   'log2', None, 'sqrt', None, 'log2'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[45, 25, 45, 10, 30, 40, 10, 5, None, 10, 10, 30, 5, 45,\n",
      "                   5, 50, 35, 30, 35, 5, 15, 50, 35, 25, None, 25, 25, 5,\n",
      "                   15, 20, 25, 40, None, 25, 40, 10, 25, 30, None, None,\n",
      "                   50, 20, 45, 35, None, 35, 45, None, 5, 45],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_estimators': 900, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 45}, {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 25}, {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 45}, {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}, {'n_estimators': 700, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 30}, {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40}, {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 10}, {'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 5}, {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': None}, {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 10}, {'n_estimators': 400, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 10}, {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}, {'n_estimators': 700, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 5}, {'n_estimators': 900, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 45}, {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 5}, {'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 50}, {'n_estimators': 900, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 35}, {'n_estimators': 800, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 30}, {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 35}, {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 5}, {'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 15}, {'n_estimators': 700, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 50}, {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 35}, {'n_estimators': 900, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 25}, {'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}, {'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 25}, {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 25}, {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 5}, {'n_estimators': 900, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 15}, {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 20}, {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 25}, {'n_estimators': 900, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': 40}, {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': None}, {'n_estimators': 1000, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 25}, {'n_estimators': 1000, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 40}, {'n_estimators': 500, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10}, {'n_estimators': 700, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 25}, {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 30}, {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': None, 'max_depth': None}, {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': None}, {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 50}, {'n_estimators': 700, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 20}, {'n_estimators': 900, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 45}, {'n_estimators': 900, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': None, 'max_depth': 35}, {'n_estimators': 700, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': None}, {'n_estimators': 1000, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 35}, {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 45}, {'n_estimators': 900, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}, {'n_estimators': 700, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': None, 'max_depth': 5}, {'n_estimators': 800, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 45}], 'split0_test_score': array([0.844, 0.84 , 0.836, 0.836, 0.828, 0.832, 0.8  , 0.844, 0.824,\n",
      "       0.836, 0.772, 0.828, 0.828, 0.832, 0.816, 0.836, 0.852, 0.82 ,\n",
      "       0.812, 0.832, 0.844, 0.828, 0.844, 0.828, 0.84 , 0.848, 0.832,\n",
      "       0.828, 0.832, 0.836, 0.84 , 0.82 , 0.848, 0.824, 0.852, 0.84 ,\n",
      "       0.844, 0.832, 0.812, 0.84 , 0.868, 0.828, 0.832, 0.812, 0.828,\n",
      "       0.836, 0.856, 0.844, 0.848, 0.84 ]), 'split1_test_score': array([0.868, 0.848, 0.86 , 0.852, 0.872, 0.864, 0.756, 0.884, 0.868,\n",
      "       0.852, 0.756, 0.864, 0.88 , 0.856, 0.844, 0.864, 0.84 , 0.848,\n",
      "       0.748, 0.852, 0.872, 0.844, 0.844, 0.872, 0.86 , 0.836, 0.856,\n",
      "       0.848, 0.856, 0.856, 0.868, 0.836, 0.856, 0.856, 0.844, 0.832,\n",
      "       0.852, 0.836, 0.868, 0.856, 0.852, 0.84 , 0.852, 0.744, 0.868,\n",
      "       0.844, 0.868, 0.88 , 0.868, 0.844]), 'split2_test_score': array([0.892, 0.868, 0.896, 0.884, 0.876, 0.876, 0.792, 0.884, 0.888,\n",
      "       0.88 , 0.796, 0.88 , 0.888, 0.884, 0.86 , 0.864, 0.884, 0.872,\n",
      "       0.792, 0.864, 0.88 , 0.888, 0.88 , 0.884, 0.888, 0.856, 0.864,\n",
      "       0.864, 0.88 , 0.884, 0.872, 0.868, 0.884, 0.872, 0.86 , 0.884,\n",
      "       0.876, 0.888, 0.86 , 0.88 , 0.884, 0.88 , 0.876, 0.792, 0.868,\n",
      "       0.884, 0.884, 0.892, 0.892, 0.884]), 'mean_test_score': array([0.868     , 0.852     , 0.864     , 0.85733333, 0.85866667,\n",
      "       0.85733333, 0.78266667, 0.87066667, 0.86      , 0.856     ,\n",
      "       0.77466667, 0.85733333, 0.86533333, 0.85733333, 0.84      ,\n",
      "       0.85466667, 0.85866667, 0.84666667, 0.784     , 0.84933333,\n",
      "       0.86533333, 0.85333333, 0.856     , 0.86133333, 0.86266667,\n",
      "       0.84666667, 0.85066667, 0.84666667, 0.856     , 0.85866667,\n",
      "       0.86      , 0.84133333, 0.86266667, 0.85066667, 0.852     ,\n",
      "       0.852     , 0.85733333, 0.852     , 0.84666667, 0.85866667,\n",
      "       0.868     , 0.84933333, 0.85333333, 0.78266667, 0.85466667,\n",
      "       0.85466667, 0.86933333, 0.872     , 0.86933333, 0.856     ]), 'std_test_score': array([0.01959592, 0.01177568, 0.02465766, 0.01995551, 0.02174601,\n",
      "       0.01857118, 0.01913693, 0.01885618, 0.02673325, 0.01818424,\n",
      "       0.01643844, 0.02174601, 0.02659992, 0.02124984, 0.01818424,\n",
      "       0.01319933, 0.01857118, 0.02124984, 0.02673325, 0.01319933,\n",
      "       0.01543445, 0.0253684 , 0.01697056, 0.02407396, 0.01968643,\n",
      "       0.00821922, 0.01359739, 0.01472715, 0.01959592, 0.01968643,\n",
      "       0.0142361 , 0.01995551, 0.01543445, 0.01995551, 0.00653197,\n",
      "       0.0228619 , 0.01359739, 0.02550817, 0.02472965, 0.01643844,\n",
      "       0.01306395, 0.02223111, 0.01798765, 0.02853458, 0.01885618,\n",
      "       0.02099735, 0.01146977, 0.02039608, 0.01798765, 0.01986622]), 'rank_test_score': array([ 5, 33,  9, 19, 15, 19, 48,  2, 13, 24, 50, 19,  7, 19, 46, 28, 15,\n",
      "       41, 47, 39,  7, 31, 24, 12, 10, 41, 37, 41, 24, 15, 13, 45, 10, 37,\n",
      "       33, 33, 19, 33, 41, 15,  5, 39, 31, 48, 28, 28,  3,  1,  3, 24]), 'split0_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'split1_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'split2_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'mean_train_score': array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]), 'std_train_score': array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dump the random search with cross validation results\n",
    "print(f\"the best score: {rf_random.best_score_}\")\n",
    "\n",
    "print(f\"the best parameters:\\n{rf_random.best_params_}\\n\")\n",
    "\n",
    "print(f\"the cross validation result:\\n{rf_random.cv_results_}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean-squared error: 0.1\n",
      "\n",
      "Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# re-build the model using the best parameters\n",
    "classifier_bestparam = GradientBoostingClassifier(n_estimators = rf_random.best_params_['n_estimators'],\n",
    "                                                 min_samples_split = rf_random.best_params_['min_samples_split'],\n",
    "                                                 min_samples_leaf = rf_random.best_params_['min_samples_leaf'],\n",
    "                                                 max_features = rf_random.best_params_['max_features'],\n",
    "                                                 max_depth = rf_random.best_params_['max_depth']\n",
    "                                                 )\n",
    "\n",
    "# train the model on split data\n",
    "classifier_bestparam.fit(x_train, y_train)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = classifier_bestparam.predict(x_val)\n",
    "\n",
    "# mean squared error\n",
    "print(f\"mean-squared error: {metrics.mean_squared_error(y_val, y_pred)}\\n\")\n",
    "\n",
    "acc = metrics.accuracy_score(y_val, y_pred)\n",
    "print(f\"Accuracy: {acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\gradient_boosting.py:1450: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Use the re-built model on whole training data\n",
    "classifier_bestparam.fit(train_data, train_label)\n",
    "\n",
    "# predict the test set\n",
    "y_pred = classifier_bestparam.predict(test_data)\n",
    "\n",
    "Id = np.arange(1, 9001)\n",
    "submit = pd.DataFrame(data = Id, columns = ['Id'])\n",
    "submit['Solution'] = y_pred\n",
    "\n",
    "submit.to_csv(\"PaulChi_Day048_HW.csv\", index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
